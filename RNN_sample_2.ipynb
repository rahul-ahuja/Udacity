{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
    "reviews = all_text.split('\\n')\n",
    "\n",
    "all_text = ' '.join(reviews)\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "reviews_ints = []\n",
    "for each in reviews:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in each.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = labels.split('\\n')\n",
    "labels = np.array([1 if each == 'positive' else 0 for each in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 1\n",
      "Maximum review length: 2514\n"
     ]
    }
   ],
   "source": [
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out that review with 0 length\n",
    "reviews_ints = [each for each in reviews_ints if len(each) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 200\n",
    "features = np.zeros((len(reviews), seq_len), dtype=int)\n",
    "for i, row in enumerate(reviews_ints):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(20000, 200) \n",
      "Validation set: \t(2500, 200) \n",
      "Test set: \t\t(2501, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, val_x = features[:split_idx], features[split_idx:]\n",
    "train_y, val_y = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(val_x)*0.5)\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 6\n",
    "lstm_layers = 1\n",
    "batch_size = 500\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_words = len(vocab)\n",
    "\n",
    "# Create the graph object\n",
    "# Add nodes to the graph\n",
    "inputs_ = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "labels_ = tf.placeholder(tf.int32, [None, None], name='labels')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of the embedding vectors (number of units in the embedding layer)\n",
    "embed_size = 15\n",
    "\n",
    "embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
    "embed = tf.nn.embedding_lookup(embedding, inputs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    # Your basic LSTM cell\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Add dropout to the cell\n",
    "drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, embed, initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "cost = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=100):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1 Iteration: 5 Train loss: 0.252\n",
      "Epoch: 0/1 Iteration: 10 Train loss: 0.253\n",
      "Epoch: 0/1 Iteration: 15 Train loss: 0.252\n",
      "Epoch: 0/1 Iteration: 20 Train loss: 0.252\n",
      "Epoch: 0/1 Iteration: 25 Train loss: 0.253\n",
      "Val acc: 0.522\n",
      "First Input Example [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0    10    65   418   775  9318    13 43897    21\n",
      "    43    28     5   278     8   214   119    21     2   353     8   136\n",
      "     8  6186     2    89    23   528   231     8    13    39  1239    22\n",
      "     3 10125 19391    17     3  3595     9     1  1454  2508     2   148\n",
      "     1    78   138    34     8   402   378    23   395    21 12661  3486\n",
      "    12    13   280    19    12    13    24     3 19322    16     3    50\n",
      "    20     8    13    43     1   573   312     1    18    12    13    85\n",
      "     7     7    10   416    40    70     3   170 11976    12    97    28\n",
      "    77   929    45     3   116    52    19   111     3  1865   331    10\n",
      "    89    23   451    12    74  1609     7     7     2    10   445     1\n",
      "   396    42  5178     4    11    18     8    13  4512    19  1451     2\n",
      "     1   797     6     3   903   100   224  1390    79    75    27  3372\n",
      "    45     4 43897    10    51  7380    21     7     7    10   236   201\n",
      "     8    45     7     7   224  1514    45     4]\n",
      "First Target Label 1\n",
      "First Predicted Label [ 0.50592691]\n",
      "Epoch: 0/1 Iteration: 30 Train loss: 0.254\n",
      "Epoch: 0/1 Iteration: 35 Train loss: 0.254\n",
      "Epoch: 0/1 Iteration: 40 Train loss: 0.252\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                pred = []\n",
    "                y_label = []\n",
    "                x_input = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x, y in get_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs_: x,\n",
    "                            labels_: y[:, None],\n",
    "                            keep_prob: 1,\n",
    "                            initial_state: val_state}\n",
    "                    batch_acc, val_state, predict = sess.run([accuracy, final_state, predictions], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                    x_input.append(x)\n",
    "                    pred.append(predict)\n",
    "                    y_label.append(y)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "                print(\"First Input Example\", x_input[0][0])\n",
    "                print(\"First Target Label\",y_label[0][0])\n",
    "                print(\"First Predicted Label\", pred[0][0])\n",
    "            iteration +=1\n",
    "    #saver.save(sess, \"./sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'really', 'liked', 'tom', 'barman', 's', 'awtwb', 'you', 'just', 'have', 'to', 'let', 'it', 'come', 'over', 'you', 'and', 'enjoy', 'it', 'while', 'it', 'lasts', 'and', 'don', 't', 'expect', 'anything', 'it', 's', 'like', 'sitting', 'on', 'a', 'caf', 'terrace', 'with', 'a', 'beer', 'in', 'the', 'summer', 'sun', 'and', 'watching', 'the', 'people', 'go', 'by', 'it', 'definitely', 'won', 't', 'keep', 'you', 'pondering', 'afterwards', 'that', 's', 'true', 'but', 'that', 's', 'not', 'a', 'prerequisite', 'for', 'a', 'good', 'film', 'it', 's', 'just', 'the', 'experience', 'during', 'the', 'movie', 'that', 's', 'great', 'br', 'br', 'i', 'felt', 'there', 'were', 'a', 'few', 'strands', 'that', 'could', 'have', 'been', 'worked', 'out', 'a', 'little', 'more', 'but', 'being', 'a', 'lynch', 'fan', 'i', 'don', 't', 'care', 'that', 'much', 'anymore', 'br', 'br', 'and', 'i', 'loved', 'the', 'style', 'or', 'flair', 'of', 'this', 'movie', 'it', 's', 'slick', 'but', 'fresh', 'and', 'the', 'soundtrack', 'is', 'a', 'beauty', 'any', 'music', 'lover', 'will', 'get', 'his', 'kicks', 'out', 'of', 'awtwb', 'i', 'can', 'assure', 'you', 'br', 'br', 'i', 'll', 'give', 'it', 'out', 'br', 'br', 'music', 'wise', 'out', 'of']\n"
     ]
    }
   ],
   "source": [
    "example2 = []\n",
    "input_examples = x_input[0][0]\n",
    "for i in range(200):\n",
    "    if input_examples[i] != 0:\n",
    "        \n",
    "        example2.append(list(vocab_to_int.keys())[list(vocab_to_int.values()).index(input_examples[i])])\n",
    "print(example2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "really\n",
      "liked\n",
      "tom\n",
      "barman\n"
     ]
    }
   ],
   "source": [
    "#vocab_to_int[\"w\"]\n",
    "print(list(vocab_to_int.keys())[list(vocab_to_int.values()).index(10)])\n",
    "print(list(vocab_to_int.keys())[list(vocab_to_int.values()).index(65)])\n",
    "print(list(vocab_to_int.keys())[list(vocab_to_int.values()).index(419)])\n",
    "print(list(vocab_to_int.keys())[list(vocab_to_int.values()).index(775)])\n",
    "print(list(vocab_to_int.keys())[list(vocab_to_int.values()).index(9153)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
