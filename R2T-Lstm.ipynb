{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of rnn_cell\n",
    "\n",
    "This is very similar to the __call__ method on Tensorflow's BasicRNNCell. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L95\n",
    "\"\"\"\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding rnn_cells to graph\n",
    "\n",
    "This is a simplified version of the \"static_rnn\" function from Tensorflow's api. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py#L41\n",
    "Note: In practice, using \"dynamic_rnn\" is a better choice that the \"static_rnn\":\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L390\n",
    "\"\"\"\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\n",
    "Losses is similar to the \"sequence_loss\"\n",
    "function from Tensorflow's API, except that here we are using a list of 2D tensors, instead of a 3D tensor. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/loss.py#L30\n",
    "\"\"\"\n",
    "\n",
    "#logits and predictions\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "# Turn our y placeholder into a list of labels\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "#losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.645333886743\n",
      "Average loss at step 200 for last 250 steps: 0.561332180202\n",
      "Average loss at step 300 for last 250 steps: 0.521056170762\n",
      "Average loss at step 400 for last 250 steps: 0.523834969103\n",
      "Average loss at step 500 for last 250 steps: 0.522091008723\n",
      "Average loss at step 600 for last 250 steps: 0.520401086211\n",
      "Average loss at step 700 for last 250 steps: 0.519225053489\n",
      "Average loss at step 800 for last 250 steps: 0.521357301474\n",
      "Average loss at step 900 for last 250 steps: 0.520775710642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fde3c97f128>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFdCAYAAACAfl7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde40a067b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
